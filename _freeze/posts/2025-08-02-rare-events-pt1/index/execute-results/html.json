{
  "hash": "89acf0e49b3db98184336eeb27e2169d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Part 1: Rare events are hard to find\"\ndescription: \"A series of posts on understanding Martin Bland's 'Detecting a single event'\"\nauthor:\n  - name: Jess Graves\ndate: 08-05-2025\ndate-modified: last-modified\nexecute-dir: project\ncrossref:\n  fig-title: '**Figure**'\n  tbl-title: '**Table**'\n  fig-labels: arabic\n  tbl-labels: arabic\n  title-delim: \".\"\nlink-citations: true\nexecute:\n  echo: true\n  warning: false\n  message: false\ncategories: [rare events, stats 101, series] \nimage: preview-image.png\ndraft: false  \n# bibliography: references.bib\nnocite: |\n  @*\n# csl: statistics-in-biosciences.csl\nbibliographystyle: apa\ncitation: true\nformat: \n  html:\n    math: \n      method: mathjax\n      tags: all\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Libraries and themes\"}\nlibrary(tidyverse) \nlibrary(paletteer)\nlibrary(colorspace)\n\npal <- \"LaCroixColoR::PeachPear\" \nbackground_col <- \"#4E5762FF\"\n\nmy_theme <- theme_classic() +\n  theme(\n    axis.text = element_text(size = 12, color = \"white\"),\n    axis.title = element_text(size = 14, color = \"white\"),\n    axis.ticks = element_blank(),\n    legend.text = element_text(size = 12, color = \"white\"), \n    legend.title = element_text(size = 14, color = \"white\"), \n    plot.caption = element_text(size = 12, color = \"white\"), \n    plot.title = element_text(size = 16, color = \"white\"), \n    plot.subtitle = element_text(size = 14, color = \"white\"), \n    axis.line = element_line(color = \"white\"),\n    panel.background = element_rect(color = background_col, fill = background_col), \n    plot.background = element_rect(color = background_col, fill = background_col),\n    legend.background = element_rect(color = background_col, fill = background_col)\n  )\n\ntheme_set(my_theme)\n```\n:::\n\n\n\n# Rare events are ... hard to find\n\n> The problem is this. If we have a series of cases where no event has taken place, what is the estimated event rate? ... Just because we have not seen an event yet does not mean we will never see one.\n>\n> \\-*Marin Bland* from *‚Äú[Detecting a single event](https://www-users.york.ac.uk/~mb55/bsi_study/single_event.pdf)\"*\n\n::: {.callout-note appearance=\"minimal\"}\nThis is the first post of what will be a series of posts reviewing Martin Bland's \"[Detecting a single event](https://www-users.york.ac.uk/~mb55/bsi_study/single_event.pdf)\" and some of the theory behind it.\n\nAs an applied statistician who spends most of my days fitting linear models and running simulations, I fall out of practice with some of the fundamentals of statistical theory. And it has been refreshing to return to the basics and be reminded of just how good they are!\n\nIn reading Bland's write up, I found I needed to re-learn a lot of things, which inspired me to start a small series covering:\n\n1.  The problem to be solved & an overview of the binomial distribution\n2.  Estimating likely event rates when zero events have been detected (exact 95% confidence intervals)\n3.  Estimating the power to detect at least 1 event in a given study[^1]¬†\n:::\n\n[^1]: No promises on how many posts this will translate to.\n\n# Zero events $\\ne$ zero risk\n\nWhy should we care about rare events? Well...rare $\\ne$ unimportant.\n\nStudying rare events come up often in research. Some examples:\n\n-   Detecting adverse events / side effects in drug development\n\n-   Monitoring safety signals in post-market drug surveillance\n\n-   Catching early signs of an outbreak in infectious disease surveillance\n\n## Adverse events in drug development\n\nLet's stick with drug development as our motivating example.\n\nI want to know if my drug is associated with a rare event that I know occurs \\~1% of the time in the general population. How many patients should I enroll to test if our drug is related to an increased risk of this event?\n\nWith an overall event rate *that low* there is a strong chance that I will simply see no events at all during the study (that's just how probability rolls üé≤ ü•Å).\n\n**Would it make sense to enroll only 5 participants?**\n\nProbably not! This is pretty intuitive. If the event happens 1% of the time, then in a N = 5 person study I'd expect:\n\n$$\n\\begin{align}\n\\text{Events} &= \\text{N} \\times \\text{Event rate} \\\\\n&= 5 \\times 0.01 = 0.05\n\\end{align}\n$$\n\nI can't observe 0.05 of an event. And most likely, I'll just see zero events.\n\n**What about 100?**\n\nBetter, but not great. With 100 participants, I would expect to see a whopping average event number of:\n\n$$\n\\text{Events} = 100 \\times 0.01 = 1\n$$\n\nAn average of 1 doesn't mean we *will* see 1. Some studies might ‚Äî but many others won‚Äôt. In fact, there‚Äôs a fairly high chance (36.6% to be exact) that I'd still see zero events in a study of 100 people, even if the true incidence is 1%.\n\n::: {.callout-important appearance=\"simple\"}\nSo, I might ask myself:\n\n1.  How many patients (N) do I need to have a high probability of seeing *at least one* event?\n    -   That is, how do I adequately power my study to ensure that it isn't a flop.\n2.  If I accidentally observe zero events in my study, what range of *true* event rates could I have plausibly missed ‚Äì just by chance?\n    -   If I enrolled 100 participants and saw zero events... is it still reasonable to believe that the true event rate might be 1%?\n:::\n\n# A walk down binomial lane\n\n## How likely will I see \\[#\\] event(s)? {#sec-how-likely-will-i-see-events}\n\nEvents are discrete ‚Äì they either happen or they don't.\n\nLet's say I flip a *fair coin* (i.e., 50/50 chance of heads or tails) 100 times. How many times will it turn heads? On average: 50 times. But as we know, real life *rarely* matches the average.\n\nSuppose I repeat the same experiment, 100 coin flips, twice:\n\n1.  In the first set, I might get 46 heads.\n2.  In the second, I might get 55.\n\n**What's the probability of getting *exactly* 50 heads** if I flip a fair coin 100 times? We can estimate this by running this same experiment 10000 times (i.e., a simulation) and see what proportion resulted in 50 heads.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nset.seed(123)\nmean(replicate(10000, \n               sum(rbinom(n = 100, size = 1, prob = 0.5)) == 50))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0759\n```\n\n\n:::\n:::\n\n\n\nRoughly 7.5% of the time.\n\n## The Binomial distribution\n\nInstead of relying on simulations, we can use the handy dandy [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) to help us quantify these probabilities by using the [probability density function](#0):\n\n$$\nf(k; n, p) = P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k} \n$$ {#eq-pdf}\n\nThat is, the probability of seeing $k$ events out of $n$ trials (or experiments), where the probability of an event is $p$. The probability of $k$ events is dependent on the $n$ trials and the $p$ event rate.\n\n## Visualizing these likelihoods\n\n### Probability of exact number of events\n\nWe can plot the probability of seeing *exactly* $k$ events for various sample sizes (@fig-pdfs). The height of the curve tells us how likely it is to see that event.\n\nTo return to our fair coin example: just like we estimated manually in @sec-how-likely-will-i-see-events, the probability of seeing exactly 50 events when you flip a fair coin 100 times is roughly 7.5%!\n\n@fig-pdfs also makes it clear how the probability of $k$ events depends heavily on the sample size. The chances of seeing exactly 25 events when we flip a coin 50 times is \\~11%, but if we flip that same coin 100 times, the chances are nearly 0.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nns <- seq(50, 100, by=10)\nks <- c(0:max(ns))\np <- 0.5\n\nexamples <- crossing(k=ks, n=ns, p) %>%\n  filter(k <= n) %>%\n  rowwise() %>%\n  mutate(prob_k = dbinom(k, n, p), \n         cum_k = pbinom(k, n, p)) \n\nexamples %>% \n  ggplot(aes(x=k, y=prob_k, color = factor(n))) + \n  annotate(\"segment\", \n           x = 50, \n           xend = 70,\n           y = dbinom(50, 100, 0.5), \n           yend = dbinom(50, 100, 0.5), \n           color = \"white\", alpha = 0.5) + \n  geom_line(linewidth=1) + \n  labs(x='k successes out of N', \n       y = 'P(X=k)', \n       color = 'Total N', \n       title = \"Probability of seeing exactly k events\",\n       caption = \"50% event rate\"\n       ) + \n  scale_color_paletteer_d(palette = pal) +\n  scale_x_continuous(breaks=scales::pretty_breaks(10), \n                     limits = c(10, 80)) + \n  scale_y_continuous(breaks=scales::pretty_breaks(10)) + \n  annotate(\"text\", \n           x = 61, \n           y = dbinom(50, 100, 0.5)+0.0075, \n           color = \"white\", \n           alpha = 0.5, \n           hjust = 0.5,\n           label = \"7.5% chance of\\nexactly 50 events\")  \n```\n\n::: {.cell-output-display}\n![Visualization of probability density function of the binomial distribution across various Ns given p = 0.5 (50% event rate).](index_files/figure-html/fig-pdfs-1.png){#fig-pdfs width=672}\n:::\n:::\n\n\n\n### Probability of *up to* k events: the cumulative distribution function\n\nTo understand how to find the probability of seeing at least a certain number of events, we first need to estimate the probability of finding *up to* a certain number of events[^2].\n\n[^2]: This might seem weird, but it is actually easier that way. See @eq-complement .\n\nTo do that, we use the [cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function), which is calculated as the cumulative sum[^3] of the probabilities (from @eq-pdf) each preceding event up to the total events you wish to see:\n\n[^3]: The [third axiom of probability](https://en.wikipedia.org/wiki/Probability_axioms#Third_axiom) tells us that for mutually exclusive events (like observing exactly 4 events vs exactly 5 events ‚Äî only one can happen in a given study), the total probability of any combination is just the sum of the individual probabilities.\n\n    In notation that's, if all events $A_i$ are mutually exclusive: $P\\left( \\bigcup_{i=1}^k A_i \\right) = \\sum_{i=1}^k P(A_i)$\n\n$$\nF(k; n, p) = P(X \\leq k) = \\sum_{k=0}^{x} \\binom{n}{k} p^k (1 - p)^{n - k} \n$$ {#eq-cdf}\n\n@fig-cdf shows us these cumulative probabilities across the same Ns as @fig-pdfs.\n\nPreviously, we saw that the likelihood that I see exactly 50 events out of 100 flips is \\~ 7.5% (@fig-pdfs) . But, what is the likelihood that I'll see *up to* 50 events? 50%.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexamples %>% \n  ggplot(aes(x=k, y=cum_k, color = factor(n))) + \n  geom_line(linewidth=1) + \n  labs(x='k successes out of N', \n       y =  expression(P(X <= k)), \n       color = \"Total N\", \n       title = \"Probability of seeing up to k events\", \n       subtitle = \"Visualization of the CDF\",\n       caption = \"50% event rate\") + \n  scale_color_paletteer_d(palette = pal) +\n  scale_x_continuous(breaks=scales::pretty_breaks(10))\n```\n\n::: {.cell-output-display}\n![Visualization of cumulative distribution function of the binomial distribution across various Ns given p = 0.5 (50% event rate).](index_files/figure-html/fig-cdf-1.png){#fig-cdf width=672}\n:::\n:::\n\n\n\n### Estimating *at least* k events\n\nBut in my study on rare adverse events, I *need* to see at least a certain number of events. So, we need a mathematical framework to answer the question:\n\n> What is the probability of seeing *at least* k events?\n\n[Laws of probability](https://en.wikipedia.org/wiki/Probability_axioms#Kolmogorov_axioms) tell us that all total probabilities sum to 1. Therefore, if we want to know how likely we are to see *at least* k events, we can simply say subtract the probability of $\\le$ k (@eq-cdf) events from 1[^4]:\n\n[^4]: See the [complementary cumulative distribution function](https://en.wikipedia.org/wiki/Cumulative_distribution_function#Complementary_cumulative_distribution_function_(tail_distribution))\n\n$$P(X>k) = 1-P(X\\le k)$$ {#eq-complement}\n\nFor the sake of easier visualization, we'll look at our fair coin again. @fig-comp-cdf shows the total probability space divided at 40 heads for a fair coin flipped 100 times and how we can calculate that there is an 82% chance I'll see \\> 40 heads.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_select <- 100\nk_select <- 45\nexample_n_20 <- examples %>% \n  mutate(n = factor(n)) %>%\n  filter(n == n_select) %>%\n  mutate(lt = k <= k_select, \n         sum = cumsum(prob_k))\n\nexample_n_20 %>%\n  ggplot(aes(x=k, y=prob_k, color = lt, fill = lt)) + \n  geom_bar(stat='identity', position = 'identity', alpha=0.9) + \n  labs(x='K successes out of N', y = 'P(x=K)', \n       caption = \"50% event rate; total N = 100\", \n       title = \"Complementary cumulative distribution\") + \n  scale_x_continuous(breaks=scales::pretty_breaks(10))  + \n  scale_y_continuous(breaks=scales::pretty_breaks(10))  + \n  theme(legend.position = 'none') +\n  scale_fill_manual(values=c('#E9A17CFF', \"white\")) + \n  scale_color_manual(values=c('#E9A17CFF', \"white\")) + \n  annotate(\"text\", \n           label = expression(P(X <= 40) == sum() ~\n                                P(X == k[italic(i)]) == 0.18), \n           color ='white',\n           x=20, y=0.06,\n           size=4, hjust=0.4)+ \n  annotate(\"text\", \n           label = \"Cumulative distribution (CDF)\", \n           color ='white', \n           x=20, y=0.065, \n           size=4, hjust=0.4) + \n  annotate(\"text\", \n           label = expression(P(X > 40) == 1 - P(X <= 40) ~ \"=\" ~ 0.82), \n           color ='#E9A17CFF', \n           x=70, y=0.06, \n           size=4, hjust=0.2)+ \n  annotate(\"text\", \n           label = \"Complementary CDF\", \n           color ='#E9A17CFF', \n           x=70, y=0.065, \n           size=4, hjust=0.3)\n```\n\n::: {.cell-output-display}\n![Illustration of the complementary cumulative distribution function.](index_files/figure-html/fig-comp-cdf-1.png){#fig-comp-cdf width=672}\n:::\n:::\n\n\n\n# What about very rare events?\n\nAlright, now we have the fundamentals of the binomial distribution. The rules are all the same, but now let's look at how the distributions look under rare event conditions.\n\nLet's return to my 1% adverse event example. @fig-pdfs-rare shows us the probability distributions for 1% incidence rates across various Ns.\n\nCompared to @fig-pdfs, these probability distributions look much less symmetric. And even among studies with large samples (e.g., N = 100), the likelihood of observing 0 events is still quite large at \\> 30%.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ns <- seq(10, 100, by=10)\nks <- c(0:max(ns))\np <- 0.01\n\nexamples <- crossing(k=ks, n=ns, p) %>%\n  filter(k <= n) %>%\n  rowwise() %>%\n  mutate(prob_k = dbinom(k, n, p), \n         cum_k = pbinom(k, n, p)) \n\nexamples %>% \n  ggplot(aes(x=k, y=prob_k, color = factor(n))) + \n  geom_line(linewidth=1) + \n  labs(x='k successes out of N', \n       y = 'P(X=k)', \n       color = 'Total N', \n       title = \"Probability of K events with a 1% event rate\") + \n  scale_color_paletteer_d(palette = pal) +\n  scale_x_continuous(breaks=scales::pretty_breaks(10), \n                     limits = c(0, 10)) + \n  scale_y_continuous(breaks=scales::pretty_breaks(10)) \n```\n\n::: {.cell-output-display}\n![Visualization of probability density function of the binomial distribution across various Ns given rare events -- p = 0.01 (1%).](index_files/figure-html/fig-pdfs-rare-1.png){#fig-pdfs-rare width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nn_select <- max(ns)\nk_select <- 0\nexample_n_10 <- examples %>% \n  mutate(n = factor(n)) %>%\n  filter(n == n_select) %>%\n  mutate(lt = k <= k_select)\n\nexample_n_10 %>%\n  ggplot(aes(x=k, y=prob_k, color = lt, fill = lt)) + \n  geom_bar(stat='identity', position = 'identity', alpha=0.9) + \n  labs(x='K successes out of N', \n       y = 'P(X=k)', \n       title = \"1 - P(x=0) tell us P(x>0)\", \n       caption = \"1% event rate; total N = 100\") + \n  scale_x_continuous(breaks=scales::pretty_breaks(10), \n                     expand = c(0.02, 0))  +\n  scale_y_continuous(breaks=scales::pretty_breaks(10))  + \n  theme(legend.position = 'none') +\n  scale_fill_manual(values=c('#E9A17CFF', \"white\")) + \n  scale_color_manual(values=c('#E9A17CFF', \"white\")) + \n  annotate(\"text\", \n           label = expression(P(X == 0) ~ \"=\" ~ 0.37), \n           color ='white',\n           x=0, y=0.40,\n           size=4, hjust = 0) + \n  annotate(\"text\", \n           label = expression(P(X > 0) == 1 - P(X == 0) ~ \"=\" ~ 0.64), \n           color ='#E9A17CFF', x=10, y=0.15, size=4, hjust=0.1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# examples |>\n#   group_by(n, p) |>\n#   arrange(n, k) |>\n#   mutate(prob_gt_0 = 1-first(prob_k)) |>\n#   dplyr::select(n, prob_gt_0) |>\n#   unique() |>\n#   ggplot(aes(x=n, y=prob_gt_0)) +\n#   geom_line(color = \"white\",\n#             linewidth = 1) +\n#   labs(x = \"Total N\",\n#        y = \"P(K > 0)\",\n#        title = \"N > 30 needed to have ~80% chance of seeing at least 1 event\\nin a study with a 5% event rate\") +\n#   scale_x_continuous(breaks = scales::pretty_breaks(10)) +\n#   scale_y_continuous(breaks = scales::pretty_breaks(5))\n```\n:::\n\n\n\n# You need very large N to see very rare events\n\nWe can generalize this across event rates and sample sizes to see that for very rare events, we need very large N.\n\nFor our 1% event rate study, we'd need to enroll at least 200 participants to get an 80% chance of seeing \\> 0 events! [^5]\n\n[^5]: Note: This is an estimate of the power of the study ‚Äì however, I want to spend a little more time on power, so will reserve more comments on this in another post.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nns <- seq(0, 200, by = 5)\nps <- c(0.001, 0.002, 0.005, 0.01, 0.02, 0.05)\nps <- ps[ps>0]\n\nexamples_ps <- crossing(k=ks, n=ns, p=ps) %>%\n  filter(k <= n) %>%\n  rowwise() %>%\n  mutate(prob_k = dbinom(k, n, p), \n         cum_k = pbinom(k, n, p)) \n\nexamples_ps_gt0 <- examples_ps |> \n  group_by(n, p) |> \n  arrange(p, n, k) |> \n  mutate(prob_gt_0 = 1-first(prob_k), \n         incidence = paste0(100*p, \"%\")) |> \n  dplyr::select(n, incidence, prob_gt_0) |> \n  unique()\n\np <- examples_ps_gt0 |>\n  ggplot(aes(x=n, y=prob_gt_0, \n             color = factor(incidence), \n             group = incidence)) + \n  geom_line(linewidth = 1) + \n  labs(x = \"Total N\", \n       y = \"Probability of at least 1 event\\nP(X > 0)\", \n       color = 'Event rate', \n       title = \"Very large N needed to observe very rare events\") + \n  scale_x_continuous(breaks = scales::pretty_breaks(10)) +\n  scale_y_continuous(breaks = scales::pretty_breaks(10)) + \n  scale_color_paletteer_d(palette = pal) \np\nggsave(\"preview-image.png\", p, \n       units='cm', \n       width = 20, \n       height = 12)\n```\n\n::: {.cell-output-display}\n![Probabilities of observing > 0 events for given event rates and sample sizes.](index_files/figure-html/fig-p-k-gt-0-1.png){#fig-p-k-gt-0 width=672}\n:::\n:::\n\n\n\n# Wrapping up Part 1\n\nAs we know, capturing rare events is hard, but not impossible. The Binomial distribution gives us a framework for thinking clearly about this uncertainty.\n\nIt helps us move from *‚ÄúI didn‚Äôt see it‚Äù* to *\"Why didn't I see it*\" and *‚ÄúHow likely was I to see it?‚Äù*.\n\nFor part 2, I‚Äôll look at how to interpret a study when **zero events** are observed: what kind of event rates are still plausible, and how to calculate exact confidence intervals around‚Ä¶ nothing at all.\n\nThanks for reading ‚Äî more soon.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}